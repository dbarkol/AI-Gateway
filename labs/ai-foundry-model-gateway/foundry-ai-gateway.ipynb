{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24875ad3",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è Microsoft Foundry\n",
    "\n",
    "## AI Foundry with APIM Model Gateway lab - Static Model Listing\n",
    "\n",
    "![flow](../../images/foundry-model-gateway.gif)\n",
    "\n",
    "This lab demonstrates how to configure Azure API Management (APIM) as a **Model Gateway** for Azure AI Foundry. By connecting APIM as a model gateway, you can leverage APIM's enterprise-grade features including rate limiting, caching, monitoring, security policies, and load balancing for AI model inference requests made through Microsoft Foundry Agents Service.\n",
    "\n",
    "### What you'll learn:\n",
    "\n",
    "- Deploy Azure AI Foundry with AI Services and model deployments\n",
    "- Configure Azure API Management with Developer SKU\n",
    "- Connect APIM as a Model Gateway to Foundry\n",
    "- Test inference requests through the APIM gateway\n",
    "- Monitor and trace gateway traffic\n",
    "\n",
    "### Architecture:\n",
    "\n",
    "```\n",
    "Foundry Agent ‚Üí APIM Gateway (Model Gateway) ‚Üí AI Services ‚Üí OpenAI Models\n",
    "                      ‚Üì\n",
    "              Policies, Monitoring,\n",
    "              Rate Limiting, Caching\n",
    "```\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r ../../requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94904a1b",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "Adjust the configuration below to customize your deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bfc5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Install required packages for Foundry v2\n",
    "%pip install requests 'azure-ai-agents>=1.2.0b5' 'azure-ai-projects>=2.0.0b1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d864ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\"\n",
    "resource_group_location = \"swedencentral\"\n",
    "\n",
    "# AI Services configuration\n",
    "aiservices_config = [{\"name\": \"models-foundry\", \"location\": \"swedencentral\", \"weight\": 1},    ## Models Foundry will be the inferencing AI service.\n",
    "                      {\"name\": \"agents-foundry\", \"location\": \"swedencentral\", \"weight\": 0}]   ## Agents Foundry shouldn't have any models deployed to it. \n",
    "\n",
    "# Models configuration\n",
    "models_config = [\n",
    "    {\"name\": \"gpt-4o-mini\", \"publisher\": \"OpenAI\", \"version\": \"2024-07-18\", \"sku\": \"GlobalStandard\", \"capacity\": 10, \"aiservice\": \"models-foundry\"},\n",
    "    {\"name\": \"gpt-4.1-mini\", \"publisher\": \"OpenAI\", \"version\": \"2025-04-14\", \"sku\": \"GlobalStandard\", \"capacity\": 10, \"aiservice\": \"models-foundry\"}\n",
    "]\n",
    "\n",
    "# APIM configuration\n",
    "apim_sku = 'Basicv2'  # Using Basicv2 SKU as specified\n",
    "apim_subscriptions_config = [\n",
    "    {\"name\": \"foundry-subscription\", \"displayName\": \"Foundry AI Gateway Subscription\"}\n",
    "]\n",
    "\n",
    "# API configuration\n",
    "inference_api_path = \"inference\"\n",
    "inference_api_type = \"PassThrough\"\n",
    "inference_api_version = \"v1\"\n",
    "foundry_project_name = \"foundry-project\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee052d",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be20f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2ea4b",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declaratively define all the resources including:\n",
    "\n",
    "- **Log Analytics Workspace** - For centralized logging\n",
    "- **Application Insights** - For monitoring and telemetry\n",
    "- **API Management (Developer SKU)** - AI Gateway with enterprise features\n",
    "- **AI Foundry** - Azure AI Services with project management\n",
    "- **Model Deployments** - OpenAI models (GPT-4o-mini)\n",
    "- **Model Gateway Connection** - Connects APIM as a gateway to Foundry\n",
    "\n",
    "The deployment also configures RBAC permissions and creates the necessary connections. Change the parameters above or the [main.bicep](main.bicep) directly to try different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c22f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resource group if it doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"aiServicesConfig\": { \"value\": aiservices_config },\n",
    "        \"modelsConfig\": { \"value\": models_config },\n",
    "        \"apimSubscriptionsConfig\": { \"value\": apim_subscriptions_config },\n",
    "        \"inferenceAPIPath\": { \"value\": inference_api_path },\n",
    "        \"inferenceAPIType\": { \"value\": inference_api_type },\n",
    "        \"foundryProjectName\": { \"value\": foundry_project_name },\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters, indent=2))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(\n",
    "    f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", \n",
    "    f\"Deployment '{deployment_name}' failed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2194045f",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the deployment outputs including gateway URLs, subscription keys, and Foundry endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(\n",
    "    f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", \n",
    "    f\"Retrieved deployment: {deployment_name}\", \n",
    "    f\"Failed to retrieve deployment: {deployment_name}\"\n",
    ")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    log_analytics_id = utils.get_deployment_output(output, 'logAnalyticsWorkspaceId', 'Log Analytics Id')\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    foundry_project_endpoint = utils.get_deployment_output(output, 'agentsfoundryProjectEndpoint', 'Foundry Project Endpoint')\n",
    "    foundry_ai_services_endpoint = utils.get_deployment_output(output, 'agentsfoundryAIServicesEndpoint', 'Foundry AI Services Endpoint')\n",
    "    model_gateway_url = utils.get_deployment_output(output, 'aiGatewayUrl', 'AI Gateway URL (APIM)')\n",
    "    model_gateway_connection = utils.get_deployment_output(output, 'aiGatewayConnectionName', 'AI Gateway Connection Name')\n",
    "    \n",
    "    apim_subscriptions = json.loads(utils.get_deployment_output(output, 'apimSubscriptions').replace(\"\\'\", \"\\\"\"))\n",
    "    for subscription in apim_subscriptions:\n",
    "        subscription_name = subscription['name']\n",
    "        subscription_key = subscription['key']\n",
    "        utils.print_info(f\"Subscription Name: {subscription_name}\")\n",
    "        utils.print_info(f\"Subscription Key: ****{subscription_key[-4:]}\")\n",
    "    \n",
    "    api_key = apim_subscriptions[0].get(\"key\")\n",
    "    \n",
    "    utils.print_ok(\"\\n‚úÖ AI Gateway Configuration Complete!\")\n",
    "    utils.print_info(f\"APIM is now configured as a AI Gateway for Foundry\")\n",
    "    utils.print_info(f\"Connection Name: {model_gateway_connection}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b24156",
   "metadata": {},
   "source": [
    "<a id='test'></a>\n",
    "### üß™ Test the APIM Model Gateway\n",
    "\n",
    "Now let's test the gateway by sending a chat completion request through APIM. The request will flow through APIM's policies before reaching the AI Services endpoint.\n",
    "\n",
    "**Tip:** Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior and troubleshoot the [policy](policy.xml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb491f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Prepare the request headers\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": api_key\n",
    "}\n",
    "\n",
    "for model in models_config:\n",
    "\n",
    "    # Construct the full API URL\n",
    "    api_url = f\"{model_gateway_url}/openai/deployments/{model['name']}/chat/completions?api-version=2024-12-01-preview\"\n",
    "\n",
    "    # Prepare the request body\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful AI assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Tell me a short joke about AI.\"\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 500,\n",
    "        \"temperature\": 0.7,\n",
    "        \"model\": model['name']\n",
    "    }\n",
    "\n",
    "    utils.print_info(f\"üöÄ Sending request to: {api_url}\")\n",
    "\n",
    "    # Send the request\n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        result = response.json()\n",
    "        \n",
    "        utils.print_ok(\"Request successful!\")\n",
    "        utils.print_info(f\"Model: {result['model']}\")\n",
    "        utils.print_info(f\"Completion tokens: {result['usage']['completion_tokens']}\")\n",
    "        utils.print_info(f\"Total tokens: {result['usage']['total_tokens']}\")\n",
    "        utils.print_info(f\"üìù Response:\")\n",
    "        print(result['choices'][0]['message']['content'] + \"\\n\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        utils.print_error(f\"‚ùå Request failed: {str(e)}\")\n",
    "        if hasattr(e.response, 'text'):\n",
    "            utils.print_error(f\"Response: {e.response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd171903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running the sample:\n",
    "#    pip install --pre azure-ai-projects>=2.0.0b1\n",
    "#    pip install azure-identity\n",
    "\n",
    "import os\n",
    "import json\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "agent_id=None\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=foundry_project_endpoint,\n",
    "    credential=credential,\n",
    ")\n",
    "\n",
    "### Set the model deployment name environment variable\n",
    "### The model name is now a path format of {model_gateway_connection}/{model_name} - only usable from SDK atm\n",
    "model = f'{model_gateway_connection}/gpt-4.1-mini'\n",
    "\n",
    "agent = project_client.agents.create_version(\n",
    "    agent_name=\"my-test-agent\",\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=model,\n",
    "        instructions='you are a helpful but sarcastic assistant.'\n",
    "    ),\n",
    ")\n",
    "print(f\"V2 Agent created (id: {agent.id}, name: {agent.name}, version: {agent.version})\")\n",
    "\n",
    "agents = project_client.agents.list()\n",
    "print(f\"\\nüìã List of agents in project '{foundry_project_endpoint}':\")\n",
    "for agent in agents:\n",
    "    print(f\"- {agent.name} (id: {agent.id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=foundry_project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "myAgent = \"my-test-agent\"\n",
    "# Get an existing agent\n",
    "agent = project_client.agents.get(agent_name=myAgent)\n",
    "utils.print_ok(f\"Retrieved agent: {agent.name}\")\n",
    "\n",
    "openai_client = project_client.get_openai_client()\n",
    "\n",
    "# it's not required but helps with the traceability of conversations in the logs to have a conversation id, especially when testing with multiple requests.\n",
    "conversation_id = openai_client.conversations.create().id\n",
    "\n",
    "# Reference the agent to get a response\n",
    "response = openai_client.responses.create(\n",
    "    input=[{\"role\": \"user\", \"content\": \"Tell me what you can help with. and tell me a funny short joke.\"}],\n",
    "    conversation=conversation_id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    ")\n",
    "\n",
    "utils.print_info(f\"üìù Response: {response.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571459af",
   "metadata": {},
   "source": [
    "<a id='verify'></a>\n",
    "### üîç Verify Model Gateway Connection in Azure Portal\n",
    "\n",
    "You can verify the Model Gateway connection in the Azure Portal:\n",
    "\n",
    "1. Navigate to your **AI Services** resource in the Azure Portal\n",
    "2. Go to **Connections** under the **Resource Management** section\n",
    "3. Look for the connection named `ai-gateway`\n",
    "4. Verify the connection type is **ApiManagement**\n",
    "5. Check that the target URL points to your APIM gateway\n",
    "\n",
    "The connection enables Foundry Agents Service to route model requests through APIM, giving you:\n",
    "- **Rate limiting** and throttling\n",
    "- **Caching** for improved performance\n",
    "- **Monitoring** and analytics\n",
    "- **Security policies** and authentication\n",
    "- **Load balancing** across multiple backends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c00702",
   "metadata": {},
   "source": [
    "<a id='monitor'></a>\n",
    "### üìä Monitor Gateway Traffic\n",
    "\n",
    "View gateway metrics and logs in:\n",
    "\n",
    "- **Application Insights**: Telemetry, performance metrics, and distributed tracing\n",
    "- **Log Analytics**: Query logs using KQL\n",
    "- **APIM Analytics**: Built-in gateway analytics and dashboards\n",
    "\n",
    "Example KQL query for Log Analytics:\n",
    "\n",
    "```kusto\n",
    "ApiManagementGatewayLogs\n",
    "| where OperationId == \"chat-completions\"\n",
    "| project TimeGenerated, Method, Url, BackendResponseCode, ResponseSize, TotalTime\n",
    "| order by TimeGenerated desc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a955c5",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundry2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
