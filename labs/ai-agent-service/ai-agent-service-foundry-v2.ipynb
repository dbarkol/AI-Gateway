{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è AI Agents\n",
    "\n",
    "## Azure AI Agent Service lab - (AI Foundry - Projects New)\n",
    "\n",
    "![flow](../../images/ai-agent-service.gif)\n",
    "\n",
    "Use this playground to explore the [Azure AI Agent Service](https://learn.microsoft.com/en-us/azure/ai-services/agents/overview), leveraging Azure API Management to control multiple services, including Logic Apps Workflows, and OpenAPI-based APIs. This enables limitless opportunities for AI agents while maintaining control through Azure API Management!\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the models and versions according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}-foundry-v2\" # change the name to match your naming style\n",
    "resource_group_location = \"eastus2\"\n",
    "\n",
    "aiservices_config = [{\"name\": \"foundry1\", \"location\": \"eastus2\"}]\n",
    "models_config = [{\"name\": \"gpt-4.1-mini\", \"publisher\": \"OpenAI\", \"version\": \"2025-04-14\", \"sku\": \"GlobalStandard\", \"capacity\": 20}]\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "apim_subscriptions_config = [{\"name\": \"subscription1\", \"displayName\": \"Subscription 1\"}]\n",
    "\n",
    "inference_api_path = \"inference\"  # path to the inference API in the APIM service\n",
    "inference_api_type = \"AzureAI\"  # options: AzureOpenAI, AzureAI, OpenAI, PassThrough\n",
    "inference_api_version = \"2024-05-01-preview\"\n",
    "foundry_project_name = deployment_name\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"aiServicesConfig\": { \"value\": aiservices_config },\n",
    "        \"modelsConfig\": { \"value\": models_config },\n",
    "        \"apimSubscriptionsConfig\": { \"value\": apim_subscriptions_config },\n",
    "        \"inferenceAPIPath\": { \"value\": inference_api_path },\n",
    "        \"inferenceAPIType\": { \"value\": inference_api_type },\n",
    "        \"foundryProjectName\": { \"value\": foundry_project_name }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main-v2.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    log_analytics_id = utils.get_deployment_output(output, 'logAnalyticsWorkspaceId', 'Log Analytics Id')\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    apim_subscriptions = json.loads(utils.get_deployment_output(output, 'apimSubscriptions').replace(\"\\'\", \"\\\"\"))\n",
    "    for subscription in apim_subscriptions:\n",
    "        subscription_name = subscription['name']\n",
    "        subscription_key = subscription['key']\n",
    "        utils.print_info(f\"Subscription Name: {subscription_name}\")\n",
    "        utils.print_info(f\"Subscription Key: ****{subscription_key[-4:]}\")\n",
    "    api_key = apim_subscriptions[0].get(\"key\") # default api key to the first subscription key\n",
    "    app_insights_name = utils.get_deployment_output(output, 'applicationInsightsName', 'Application Insights Name')\n",
    "    foundry_project_endpoint = utils.get_deployment_output(output, 'foundryProjectEndpoint', 'Foundry Project Endpoint')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4Ô∏è‚É£ List the connections\n",
    "\n",
    "Retrieve the connections managed in AI Foundry available for the Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade azure-ai-projects>=2.0.0b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient(credential=DefaultAzureCredential(),\n",
    "    endpoint=foundry_project_endpoint)\n",
    "with project_client:\n",
    "    connections = project_client.connections.list()\n",
    "    for connection in connections:\n",
    "        utils.print_info(f\"Name: {connection.name}, Id: {connection.id}, Type: {connection.type}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='quickstart'></a>\n",
    "### üß™ Create and run a Math Tutor Agent with AI Foundry Agents API\n",
    "\n",
    "Check the official documentation for updates on this quickstart:\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/agents/quickstart\n",
    "\n",
    "***Important: This cell is prone to high latency due to the adhoc nature of creating a codeinterpreter container - 3-5 mins***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import PromptAgentDefinition, CodeInterpreterTool, CodeInterpreterToolAuto\n",
    "\n",
    "\n",
    "# Create an Azure AI Client from an endpoint, copied from your Azure AI Foundry project.\n",
    "# You need to login to Azure subscription via Azure CLI and set the environment variables\n",
    "\n",
    "# Create an AIProjectClient instance\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=foundry_project_endpoint,\n",
    "    credential=DefaultAzureCredential(),  # Use Azure Default Credential for authentication\n",
    ")\n",
    "agents_client = project_client.agents\n",
    "\n",
    "# Initialize the Code Interpreter tool with auto container and no pre-uploaded files\n",
    "code_interpreter = CodeInterpreterTool(container=CodeInterpreterToolAuto(file_ids=[]))\n",
    "\n",
    "with project_client:\n",
    "    agent = agents_client.create_version(\n",
    "        definition=PromptAgentDefinition(\n",
    "            model=str(models_config[0].get('name')),\n",
    "            instructions=\"You are a personal math tutor. Answer questions briefly, in a sentence or less.\",\n",
    "            tools=[code_interpreter]\n",
    "        ),\n",
    "        agent_name=\"my-maths-agent\"\n",
    "    )\n",
    "    utils.print_ok(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    openai_client = project_client.get_openai_client()\n",
    "    conversation_id = openai_client.conversations.create().id\n",
    "    utils.print_ok(f\"Created thread, ID: {conversation_id}\")\n",
    "    \n",
    "    # Create message to thread\n",
    "    response = openai_client.responses.create(\n",
    "        input=[{\"role\": \"user\", \"content\": \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"}],\n",
    "        conversation=conversation_id,\n",
    "        extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    )\n",
    "    \n",
    "    # Fetch and log all messages\n",
    "    print(f\"\\nüó®Ô∏è Agent: {response.output_text}\")\n",
    "    \n",
    "    ### Clean up resources\n",
    "    # agents_client.delete_version(agent_name=agent.name, agent_version=agent.version)\n",
    "    # utils.print_ok(\"Deleted agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bing'></a>\n",
    "### üß™ Grounding with Bing\n",
    "\n",
    "Check the official documentation for updates on this sample: https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/bing-grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import ListSortOrder, MessageTextContent\n",
    "from azure.ai.projects.models import PromptAgentDefinition, BingGroundingAgentTool, BingGroundingSearchToolParameters, BingGroundingSearchConfiguration\n",
    "\n",
    "prompt_content = \"What are the top 5 news headlines today from the UK?\"\n",
    "\n",
    "# Create an AIProjectClient instance\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=foundry_project_endpoint,\n",
    "    credential=DefaultAzureCredential(),  # Use Azure Default Credential for authentication\n",
    ")\n",
    "agents_client = project_client.agents\n",
    "\n",
    "bing_connection = project_client.connections.get(name='bingSearch-connection')\n",
    "conn_id = bing_connection.id\n",
    "\n",
    "# Initialize agent bing tool and add the connection id\n",
    "\n",
    "bing = BingGroundingAgentTool(\n",
    "        bing_grounding=BingGroundingSearchToolParameters(\n",
    "            search_configurations=[\n",
    "                BingGroundingSearchConfiguration(\n",
    "                    project_connection_id=conn_id,\n",
    "                    market=\"en-gb\",             # specify market for localized results, e.g. \"en-GB\" for UK\n",
    "                    set_lang=\"en\",\n",
    "                    count=5\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Create agent with the bing tool and process assistant run\n",
    "with project_client:\n",
    "    bing_agent = agents_client.create_version(\n",
    "        definition=PromptAgentDefinition(\n",
    "            model=str(models_config[0].get('name')),\n",
    "            instructions=\"Provide concise and accurate answers based on the search results in bullet points for easy reading.\",\n",
    "            tools=[bing]\n",
    "        ),\n",
    "        agent_name=\"my-bing-assistant\",\n",
    "        headers={\"x-ms-enable-preview\": \"true\"})   \n",
    "    utils.print_ok(f\"Created agent, ID: {bing_agent.id}\")\n",
    "\n",
    "    openai_client = project_client.get_openai_client()\n",
    "    conversation_id = openai_client.conversations.create().id\n",
    "    utils.print_ok(f\"Created thread, ID: {conversation_id}\")\n",
    "\n",
    "    # Create message to thread\n",
    "    response = openai_client.responses.create(\n",
    "        input=[{\"role\": \"user\", \"content\": \"What's the latest news from the UK?\"}],\n",
    "        conversation=conversation_id,\n",
    "        extra_body={\"agent\": {\"name\": bing_agent.name, \"type\": \"agent_reference\"}},\n",
    "    )   \n",
    "\n",
    "    # Fetch and log all messages\n",
    "    print(f\"\\nüó®Ô∏è Agent: {response.output_text}\")\n",
    "\n",
    "    ### Clean up resources\n",
    "    # agents_client.delete_version(agent_name=bing_agent.name, agent_version=bing_agent.version)\n",
    "    # utils.print_ok(\"Deleted agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='weatherapi'></a>\n",
    "### üß™ Run agent with Weather OpenAPI from Azure API Management\n",
    "\n",
    "üëâ Check the [Azure AI Foundry Tracing](https://learn.microsoft.com/en-us/azure/ai-studio/concepts/trace) information to understand the execution process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "\n",
    "credential=DefaultAzureCredential()\n",
    "project_client=AIProjectClient(endpoint=foundry_project_endpoint, credential=credential)\n",
    "openai_client=project_client.get_openai_client()\n",
    "\n",
    "prompt_content = \"Return a summary of the temperature in Seattle and 3 other sister cities in Europe?\"\n",
    "\n",
    "# Load OpenAPI specification for weather API\n",
    "with open(\"./city-weather-openapi.json\", \"r\") as f:\n",
    "    openapi_weather = json.loads(f.read().replace(\"https://replace-me.local/weatherservice\", f\"{apim_resource_gateway_url}/weatherservice\"))\n",
    "\n",
    "# Initialize agent OpenAPI tool using dictionary-based definition\n",
    "weather_tool = {\n",
    "    \"type\": \"openapi\",\n",
    "    \"openapi\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Retrieve weather information for a location\",\n",
    "        \"spec\": openapi_weather,\n",
    "        \"auth\": {\n",
    "            \"type\": \"project_connection\",\n",
    "            \"security_scheme\": {\n",
    "                \"project_connection_id\": project_client.connections.get(\"WeatherAPI\").id\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create agent with chained context managers\n",
    "weather_agent = project_client.agents.create_version(\n",
    "    agent_name=\"my-weather-agent\",\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=str(models_config[0].get('name')),\n",
    "        instructions=\"You are a helpful agent that provides weather information for cities around the world.\",\n",
    "        tools=[weather_tool],\n",
    "    ),\n",
    "    description=\"Weather information assistant\",\n",
    ")\n",
    "utils.print_ok(f\"Created agent (id: {weather_agent.id}, name: {weather_agent.name}, version: {weather_agent.version})\")\n",
    "\n",
    "conversation_id = openai_client.conversations.create().id\n",
    "utils.print_ok(f\"Created conversation, ID: {conversation_id}\")\n",
    "\n",
    "print(f\"\\nüó®Ô∏è User: {prompt_content}\")\n",
    "response = openai_client.responses.create(\n",
    "    input=[{\"role\": \"user\", \"content\": prompt_content}],\n",
    "    conversation=conversation_id,\n",
    "    extra_body={\"agent\": {\"name\": weather_agent.name, \"type\": \"agent_reference\"}},\n",
    ")\n",
    "print(f\"\\nüó®Ô∏è Agent: {response.output_text}\")\n",
    "\n",
    "# print(\"\\nCleaning up...\")\n",
    "# project_client.agents.delete_version(agent_name=weather_agent.name, agent_version=weather_agent.version)\n",
    "# utils.print_ok(\"Agent deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='logicapp'></a>\n",
    "### üß™ Run agent operations with MCP Backend and Logic Apps workflow\n",
    "\n",
    "‚öôÔ∏è **Tools**:\n",
    "- Get Product Catalog - OpenAPI Backend mocked with an APIM policy.\n",
    "- Place Order - A Logic Apps workflow that processes orders with a maximum of five items.\n",
    "\n",
    "‚ú® **Expected Behavior**:\n",
    "- The agent receives a user request to order 11 smartphones.\n",
    "- The agent calls the product catalog API to retrieve the product SKU and available stock quantity.\n",
    "- If the order quantity exceeds available stock, the agent will respond that the order cannot be processed due to insufficient stock.\n",
    "- If stock is available, the agent will initiate the order workflow, which will fail because the quantity exceeds the maximum limit of five items.\n",
    "- As the agent was instructed to recover from errors, it will place multiple orders, each with a quantity below the maximum limit, ensuring the total equals the desired order quantity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "credential=DefaultAzureCredential()\n",
    "project_client=AIProjectClient(endpoint=foundry_project_endpoint, credential=credential)\n",
    "openai_client=project_client.get_openai_client()\n",
    "\n",
    "prompt_content = \"List the available smartphones in the catalog and place an order for one of each for me and my 10 friends.\"\n",
    "\n",
    "# Load OpenAPI specifications\n",
    "with open(\"./product-catalog-openapi.json\", \"r\") as f:\n",
    "    openapi_product_catalog = json.loads(f.read().replace(\"https://replace-me.local/catalogservice\", f\"{apim_resource_gateway_url}/catalogservice\"))\n",
    "\n",
    "with open(\"./place-order-openapi.json\", \"r\") as f:\n",
    "    openapi_place_order = json.loads(f.read().replace(\"https://replace-me.local/orderservice\", f\"{apim_resource_gateway_url}/orderservice\"))\n",
    "\n",
    "# Initialize agent OpenAPI tools using dictionary-based definitions\n",
    "product_catalog_tool = {\n",
    "    \"type\": \"openapi\",\n",
    "    \"openapi\": {\n",
    "        \"name\": \"get_product_catalog\",\n",
    "        \"description\": \"Retrieve the list of products available in the catalog\",\n",
    "        \"spec\": openapi_product_catalog,\n",
    "        \"auth\": {\n",
    "            \"type\": \"project_connection\",\n",
    "            \"security_scheme\": {\n",
    "                \"project_connection_id\": project_client.connections.get(\"ProductCatalogAPI\").id\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "place_order_tool = {\n",
    "    \"type\": \"openapi\",\n",
    "    \"openapi\": {\n",
    "        \"name\": \"place_order\",\n",
    "        \"description\": \"Place a product order\",\n",
    "        \"spec\": openapi_place_order,\n",
    "        \"auth\": {\n",
    "            \"type\": \"project_connection\",\n",
    "            \"security_scheme\": {\n",
    "                \"project_connection_id\": project_client.connections.get(\"PlaceOrderAPI\").id\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create agent with chained context managers\n",
    "orders_agent = project_client.agents.create_version(\n",
    "    agent_name=\"my-orders-agent\",\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=str(models_config[0].get('name')),\n",
    "        instructions=\"You are a helpful sales assistant that helps users order products. Recover from errors if any and place multiple orders if needed.\",\n",
    "        tools=[product_catalog_tool, place_order_tool],\n",
    "    ),\n",
    "    description=\"You are a helpful sales assistant.\",\n",
    ")\n",
    "utils.print_ok(f\"Created agent (id: {orders_agent.id}, name: {orders_agent.name}, version: {orders_agent.version})\")\n",
    "\n",
    "conversation_id = openai_client.conversations.create().id\n",
    "utils.print_ok(f\"Created conversation, ID: {conversation_id}\")\n",
    "\n",
    "print(f\"\\nüó®Ô∏è User: {prompt_content}\")\n",
    "response = openai_client.responses.create(\n",
    "    input=[{\"role\": \"user\", \"content\": prompt_content}],\n",
    "    conversation=conversation_id,\n",
    "    extra_body={\"agent\": {\"name\": orders_agent.name, \"type\": \"agent_reference\"}},\n",
    ")\n",
    "print(f\"\\nüó®Ô∏è Agent: {response.output_text}\")\n",
    "\n",
    "# print(\"\\nCleaning up...\")\n",
    "# project_client.agents.delete_version(agent_name=orders_agent.name, agent_version=orders_agent.version)\n",
    "# utils.print_ok(\"Agent deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Analyze Application Insights custom metrics with a KQL query\n",
    "\n",
    "With this query you can get the custom metrics that were emitted by Azure APIM. Note that it may take a few minutes for data to become available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\\\"\" + \"customMetrics \\\n",
    "| where name == 'Total Tokens' \\\n",
    "| where timestamp >= ago(1h) \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription ID']) \\\n",
    "| extend agentID = tostring(parsedCustomDimensions.['Agent ID']) \\\n",
    "| summarize TotalValue = sum(value) by apimSubscription, bin(timestamp, 1m), agentID \\\n",
    "| order by timestamp asc\" + \"\\\"\"\n",
    "\n",
    "output = utils.run(f\"az monitor app-insights query --app {app_insights_name} -g {resource_group_name} --analytics-query {query}\",\n",
    "    f\"App Insights query succeeded\", f\"App Insights query  failed\")\n",
    "\n",
    "table = output.json_data['tables'][0]\n",
    "df = pd.DataFrame(table.get(\"rows\"), columns = [col.get(\"name\") for col in table.get('columns')])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%H:%M')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### üîç Plot the custom metrics results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "if df.empty:\n",
    "    print(\"No data to plot\")\n",
    "else:\n",
    "    df_pivot = df.pivot(index='timestamp', columns='apimSubscription', values='TotalValue')\n",
    "    ax = df_pivot.plot(kind='bar', stacked=True)\n",
    "    plt.title('Total token usage over time by APIM Subscription')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Tokens')\n",
    "    plt.legend(title='APIM Subscription')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundry2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
